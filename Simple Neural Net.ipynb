{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Nets Experiment\n",
    "\n",
    "Basically what we do in a neural net:\n",
    "1. We have a fixed input and a desired output\n",
    "2. Create a random output, that will turn into predicted output, that we estimate by using a function\n",
    "3. In every iteration we aproximate the predicted output to the desired output\n",
    "4. When the output is close enough, we can extend the result to other inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# examples of training data\n",
    "training_input = np.array([[0,0,1], [1,1,1], [1,0,1], [0,1,0]])\n",
    "#T because its the transposition of the array\n",
    "training_output = np.array([[0,1,1,0]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self):\n",
    "        # random number generator\n",
    "        np.random.seed(1)\n",
    "        # single neuron with 3 input conections\n",
    "        self.synaptic_weights = 2 * np.random.random((3, 1)) - 1\n",
    "        # sigmoid function that receive the weighted sum of the inputs and normalize them between 0 and 1\n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    # sigmoid derivative that indicates how confident is the random weights that we're created\n",
    "    def __sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    def train(self, input_set, output_set, iterations):\n",
    "        for iteration in iter(range(iterations)):\n",
    "            # pass the input set through the neural net (that we fixed for one neuron)\n",
    "            output = self.think(input_set)\n",
    "\n",
    "            # calculate the error (diference between the desired and the predicted output)\n",
    "            error = output_set - output\n",
    "\n",
    "            # adjust the accuracy by multiplying the error by the input and by the derivate of the curve\n",
    "            # that means that the most confident weights are adjusted, and those that don't need are not adjusted\n",
    "            # np.dot(): matrix multiplication\n",
    "            adjustment = np.dot(input_set.T, error * self.__sigmoid_derivative(output))\n",
    "\n",
    "            # ajust the weigths for the next iteration\n",
    "            self.synaptic_weights += adjustment\n",
    "\n",
    "            if (iteration % 1000 == 0):\n",
    "                print (\"error after %s iterations: %s\" % (iteration, str(np.mean(np.abs(error)))))\n",
    "    # think function estimate the output\n",
    "    def think(self, input_set):\n",
    "        # pass the input to our neural net\n",
    "        return self.__sigmoid(np.dot(input_set, self.synaptic_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random starting synaptic weights: \n",
      "[[-0.16595599]\n",
      " [ 0.44064899]\n",
      " [-0.99977125]]\n",
      "error after 0 iterations: 0.578374046722\n",
      "error after 1000 iterations: 0.0353771814512\n",
      "error after 2000 iterations: 0.024323319584\n",
      "error after 3000 iterations: 0.0196075022358\n",
      "error after 4000 iterations: 0.016850233908\n",
      "error after 5000 iterations: 0.014991814044\n",
      "error after 6000 iterations: 0.0136320935305\n",
      "error after 7000 iterations: 0.01258242301\n",
      "error after 8000 iterations: 0.0117408289409\n",
      "error after 9000 iterations: 0.0110467781322\n",
      "Considering new situation [0, 1, 0] -> ?: \n",
      "[ 0.01453999]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # initialize the neural net\n",
    "    neural_net = NeuralNetwork()\n",
    "    \n",
    "    # generate the random output that will be estimated\n",
    "    print (\"Random starting synaptic weights: \")\n",
    "    print (neural_net.synaptic_weights)\n",
    "    \n",
    "    # Train the neural network using a training set.\n",
    "    # Do it 10,000 times and make small adjustments each time.\n",
    "    neural_net.train(training_input, training_output, 10000)\n",
    "    \n",
    "    # Test the neural network with a new pattern\n",
    "    test = [0, 1, 0]\n",
    "    print (\"Considering new situation %s -> ?: \" % test )\n",
    "    print (neural_net.think(np.array(test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
